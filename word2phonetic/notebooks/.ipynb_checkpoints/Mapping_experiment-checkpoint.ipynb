{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/anaconda3/envs/1.5_cpu/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Communication to TensorFlow server via gRPC\n",
    "from grpc.beta import implementations\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow serving stuff to send messages\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "from scipy.io import loadmat\n",
    "from copy import deepcopy\n",
    "from flask import send_file\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VOCAB_BASED_LANGUAGES = [\"en\"]\n",
    "\n",
    "LANGUAGE = \"en\"\n",
    "MODEL_NAME = \"w2p_\" + LANGUAGE\n",
    "\n",
    "if LANGUAGE in VOCAB_BASED_LANGUAGES:\n",
    "    VOCAB = \"../api/word_to_phonetic/\"+LANGUAGE+\"/vocab\"\n",
    "else:\n",
    "    VOCAB = None\n",
    "    \n",
    "DATASET = \"../data_dir/\"+LANGUAGE+\"/dataset.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _char_encode(input, padding_to = None):\n",
    "    \"\"\"\n",
    "    Transform txt input to int tokens\n",
    "    +2 is for special tokens [\"<EOS>\", \"<PAD>\"]\n",
    "    + [1] is to add end of sequence \"<EOS>\" token\n",
    "\n",
    "    :param input: String input\n",
    "    :return: [1, -1, 1, 1] Int array\n",
    "    \"\"\"\n",
    "    inp = [c + 2 for c in input.encode(\"Latin-1\")] + [1]\n",
    "    if padding_to:\n",
    "        for _ in range(padding_to - len(inp)):\n",
    "            inp += [0]\n",
    "    inp = np.reshape(inp, [1, -1, 1, 1])\n",
    "\n",
    "    return inp\n",
    "\n",
    "def _char_decode(input):\n",
    "    \"\"\"\n",
    "    Decode token ids to string and removes padding and eos\n",
    "\n",
    "    :param input: int array\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "\n",
    "    return [chr(idx - 2) for idx in input if idx > 1]\n",
    "\n",
    "def _vocab_encode(input, vocab, padding_to = None):\n",
    "    with open(vocab, \"r\") as f:\n",
    "        vocab_arr = [l.strip()[1:-1] for l in f.readlines()]\n",
    "    \n",
    "    try :\n",
    "        inp = [np.where(np.array(vocab_arr) == (c.upper() + \"_\"))[0][0] for c in input] + [1]\n",
    "    except :\n",
    "        print(input)\n",
    "    if padding_to:\n",
    "        for _ in range(padding_to - len(inp)):\n",
    "            inp += [0]\n",
    "    inp = np.reshape(inp, [1, -1, 1, 1])\n",
    "    return inp\n",
    "\n",
    "def _vocab_decode(input, vocab):\n",
    "    with open(vocab, \"r\") as f:\n",
    "        vocab_arr = [l.strip()[1:-1] for l in f.readlines()]\n",
    "    return [vocab_arr[i][:-1] for i in input if i>1]\n",
    "\n",
    "def _create_translate_request(input, model_name):\n",
    "    \"\"\"\n",
    "    Creates translate request to TensorFlow serving server\n",
    "\n",
    "    :param input: Int array, token ids\n",
    "    :param model_name: Name of the model to serve\n",
    "    :return: PredictRequest object\n",
    "    \"\"\"\n",
    "    # create predict request\n",
    "    request = predict_pb2.PredictRequest()\n",
    "\n",
    "    # Call model to make phonetic translation\n",
    "    request.model_spec.name = model_name\n",
    "    request.model_spec.signature_name = \"get_phon\"\n",
    "    request.inputs['input'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(input, dtype=tf.int32))\n",
    "\n",
    "    return request\n",
    "\n",
    "\n",
    "def _create_att_mats_request(input, phon, model_name):\n",
    "    \"\"\"\n",
    "    Creates attention matrices request to TensorFlow serving server\n",
    "\n",
    "    :param input: Int array, token ids\n",
    "    :param phon: Int array, token ids, result of the phonetic translation\n",
    "    :param model_name: name of the model to serve\n",
    "    :return: PredictRequest object\n",
    "    \"\"\"\n",
    "\n",
    "    # create predict request\n",
    "    request = predict_pb2.PredictRequest()\n",
    "\n",
    "    # Call model to get the correct attention matrices\n",
    "    request.model_spec.name = model_name\n",
    "    request.model_spec.signature_name = \"get_att_mats\"\n",
    "    request.inputs[\"input\"].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(input, dtype=tf.int32))\n",
    "    request.inputs[\"phon\"].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(phon, dtype=tf.int32))\n",
    "\n",
    "    return request\n",
    "\n",
    "def _open_tf_server_channel(server_name, server_port):\n",
    "    \"\"\"\n",
    "    Opens channel to TensorFlow server for requests\n",
    "\n",
    "    :param server_name: String, server name (localhost, IP address)\n",
    "    :param server_port: String, server port\n",
    "    :return: Channel stub\n",
    "    \"\"\"\n",
    "    channel = implementations.insecure_channel(\n",
    "        server_name,\n",
    "        int(server_port))\n",
    "    stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "\n",
    "    return stub\n",
    "\n",
    "def _format_phon(phon):\n",
    "    values = phon.int_val\n",
    "    shape1 = phon.tensor_shape.dim[0].size\n",
    "    shape2 = phon.tensor_shape.dim[1].size\n",
    "\n",
    "    return np.reshape(values, [shape1, shape2])\n",
    "\n",
    "def _format_att_mat(att_mat):\n",
    "    values = att_mat.float_val\n",
    "    shape1 = att_mat.tensor_shape.dim[0].size\n",
    "    shape2 = att_mat.tensor_shape.dim[1].size\n",
    "    \n",
    "    if len(att_mat.tensor_shape.dim) == 2:\n",
    "        return np.reshape(values, [shape1, shape2])\n",
    "    elif len(att_mat.tensor_shape.dim) == 3:\n",
    "        shape3 = att_mat.tensor_shape.dim[2].size\n",
    "        return np.reshape(values, [shape1, shape2, shape3])\n",
    "\n",
    "\n",
    "def _make_translation(input, model_name, stub):\n",
    "    translation_request = _create_translate_request(input, model_name)\n",
    "    translation_results = stub.Predict(translation_request, 60.0)\n",
    "    return _format_phon(translation_results.outputs[\"phon\"])\n",
    "\n",
    "\n",
    "def _make_att_matrices(input, phon, model_name, stub):\n",
    "    att_mats_request = _create_att_mats_request(input, phon, model_name)\n",
    "    att_mats_results = stub.Predict(att_mats_request, 60.0)\n",
    "\n",
    "    att_mats = []\n",
    "    att_mats.append(_format_att_mat(att_mats_results.outputs[\"att_mat_inp_out_layer_0\"]))\n",
    "    att_mats.append(_format_att_mat(att_mats_results.outputs[\"att_mat_inp_out_layer_4\"]))\n",
    "    att_mats.append(_format_att_mat(att_mats_results.outputs[\"att_mat_inp_out_layer_5\"]))\n",
    "\n",
    "    return np.array(att_mats)\n",
    "\n",
    "\n",
    "def _make_prediction(input, model_name, stub, vocab=None):\n",
    "    if not vocab:\n",
    "        input_tokenized = _char_encode(input)\n",
    "    else:\n",
    "        input_tokenized = _vocab_encode(input, vocab)\n",
    "\n",
    "    phon_tokenized = np.squeeze(_make_translation(input_tokenized, model_name, stub))\n",
    "\n",
    "    if not vocab:\n",
    "        phon = _char_decode(phon_tokenized)\n",
    "    else:\n",
    "        phon = _vocab_decode(phon_tokenized, vocab)\n",
    "\n",
    "    att_mats = _make_att_matrices(input_tokenized, np.reshape(phon_tokenized, [1, -1, 1, 1]), model_name, stub)\n",
    "\n",
    "    sum_all_layers = _normalize(np.sum(np.array(att_mats), axis=0)[:len(phon), :len(input)])\n",
    "\n",
    "    return phon, sum_all_layers\n",
    "\n",
    "def _make_prediction_batch(batch_input, model_name, stub, vocab=None):\n",
    "    padding_to = len(max(batch_input, key=len)) + 1\n",
    "    \n",
    "    if not vocab:\n",
    "        batch_input_tokenized = np.stack([_char_encode(input, padding_to).squeeze(0) for input in batch_input], 0)\n",
    "\n",
    "    else:\n",
    "        batch_input_tokenized = np.stack([_vocab_encode(input, vocab, padding_to).squeeze(0) for input in batch_input], 0)\n",
    "\n",
    "    batch_phon_tokenized = _make_translation(batch_input_tokenized, model_name, stub)\n",
    "\n",
    "    if not vocab:\n",
    "        batch_phon = [_char_decode(phon_tokenized) for phon_tokenized in batch_phon_tokenized]\n",
    "    else:\n",
    "        batch_phon = [_vocab_decode(phon_tokenized, vocab) for phon_tokenized in batch_phon_tokenized]\n",
    "    \n",
    "    batch_att_mats = _make_att_matrices(batch_input_tokenized, np.reshape(batch_phon_tokenized, [len(batch_input), -1, 1, 1]), model_name, stub)\n",
    "\n",
    "    batch_sum_all_layers = _normalize(np.sum(np.array(batch_att_mats), axis=0))\n",
    "\n",
    "    return batch_phon, batch_sum_all_layers\n",
    "\n",
    "\n",
    "def g2p_mapping_once(input, model_name, vocab=None):\n",
    "    \"\"\"\n",
    "    Predict the phonetic translation of a word using a Transformer model\n",
    "\n",
    "    :param input: String, word\n",
    "    :param model_name: Name of the model to serve\n",
    "    :return: Array[3], [0] input text, [1] phonetic translation, [2] mapping\n",
    "    \"\"\"\n",
    "\n",
    "    # get TensorFlow server connection parameters\n",
    "    server_name, server_port = \"0.0.0.0\", \"9000\"\n",
    "\n",
    "    # open channel to tensorflow server\n",
    "    stub = _open_tf_server_channel(server_name, server_port)\n",
    "\n",
    "    # get phonetic translation and attention matrices\n",
    "    phon, sum_all_layers = _make_prediction(input, model_name, stub, vocab)\n",
    "\n",
    "    # make prediction\n",
    "\n",
    "    return _mapping(input, phon, sum_all_layers)\n",
    "\n",
    "def g2p_mapping_batch(batch_input, model_name, vocab=None):\n",
    "    \"\"\"\n",
    "    Predict the phonetic translation of a word using a Transformer model\n",
    "\n",
    "    :param input: String, word\n",
    "    :param model_name: Name of the model to serve\n",
    "    :return: Array[3], [0] input text, [1] phonetic translation, [2] mapping\n",
    "    \"\"\"\n",
    "\n",
    "    # get TensorFlow server connection parameters\n",
    "    server_name, server_port = \"0.0.0.0\", \"9000\"\n",
    "\n",
    "    # open channel to tensorflow server\n",
    "    stub = _open_tf_server_channel(server_name, server_port)\n",
    "\n",
    "    # get phonetic translation and attention matrices\n",
    "    batch_phon, batch_sum_all_layers = _make_prediction_batch(batch_input, model_name, stub, vocab)\n",
    "\n",
    "    # make prediction\n",
    "    return [_mapping(input, batch_phon[idx], batch_sum_all_layers[idx, :len(batch_phon[idx]), :len(input)]) for idx, input in enumerate(batch_input)]\n",
    "\n",
    "def g2p_mapping_file(corpus, progression, model_name, vocab=None):\n",
    "    gpProg = _load_gp_prog(progression)\n",
    "\n",
    "    # get TensorFlow server connection parameters\n",
    "    server_name, server_port = \"0.0.0.0\", \"9000\"\n",
    "\n",
    "    # open channel to tensorflow server\n",
    "    stub = _open_tf_server_channel(server_name, server_port)\n",
    "\n",
    "    # get phonetic translation and attention matrices\n",
    "    phon_results = []\n",
    "    g_p_results = []\n",
    "    for word in corpus:\n",
    "        phon, sum_all_layers = _make_prediction(word, model_name, stub, vocab)\n",
    "        phon_results.append(phon)\n",
    "        g_p_results.append(_mapping(word, phon, sum_all_layers)[2])\n",
    "\n",
    "    wordGp = list(zip(corpus, phon_results, deepcopy(g_p_results), deepcopy(g_p_results)))\n",
    "    wordGp = _get_unique_words(wordGp)\n",
    "    wordList = _generate_word_list(wordGp, gpProg)\n",
    "\n",
    "    path = os.path.join(settings.FR_FILES, \"results.csv\")\n",
    "    wordList.to_csv(path, encoding=\"UTF-8\")\n",
    "    return send_file(path)\n",
    "\n",
    "def _normalize(matrix):\n",
    "    \"\"\"\n",
    "        input: a numpy matrix\n",
    "        return: matrix with 0 mean and 1 std\n",
    "    \"\"\"\n",
    "    return (matrix - np.mean(matrix)) / (np.std(matrix) + 1e-10)\n",
    "\n",
    "\n",
    "def _mapping(inp_text, out_text, sum_all_layers):\n",
    "    # Base threshold\n",
    "    # fr : 0.75\n",
    "    # es : 0.4\n",
    "    if len(out_text) > 4:\n",
    "        threshold = 0.4\n",
    "    else:\n",
    "        threshold = 0\n",
    "\n",
    "    # While we have too many silent_letters detected\n",
    "    while (True):\n",
    "        # Gets the silent_letters indices\n",
    "        # We consider that a letter is silent if its attention value is below mean attention + threshold * std attention\n",
    "        silent_letters_idx = [i for i, idx in enumerate(np.argmax(sum_all_layers, axis=0))\n",
    "                              if sum_all_layers[idx, i] < np.mean(sum_all_layers[idx, :])\n",
    "                              + threshold * np.std(sum_all_layers[idx, :])]\n",
    "        # Reduces threshold if too many silent letters are detected\n",
    "        # Can happen in french when we have 3 lettres graphemes\n",
    "        if len(silent_letters_idx) > 1 / 3 * len(inp_text):\n",
    "            threshold -= 0.1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Creates the phoneme attribution list\n",
    "    phon_list = np.array(out_text)[np.argmax(sum_all_layers, axis=0)]\n",
    "    phon_list[silent_letters_idx] = \"#\"  # \"#\" is our encoding for silent letters\n",
    "    phon_list = phon_list.tolist()  # needed for the += just below\n",
    "\n",
    "    # Checks if all the phonemes are attributed and if they are only present the correct number of time in the list\n",
    "    # If not, the phoneme is concatenated to its most probable neighbor\n",
    "    # and the least probable phoneme is replaced by a silent letter (this can happen for small datasets)\n",
    "    discard_next = False\n",
    "    for i, phon in enumerate(out_text):\n",
    "        if phon not in phon_list and not discard_next:\n",
    "            probable_idx = np.argmax(sum_all_layers[i, :])\n",
    "            if (i+1) < len(out_text) and phon_list[probable_idx] == out_text[i+1]:\n",
    "                phon_list[probable_idx] = phon + phon_list[probable_idx]\n",
    "                discard_next = True\n",
    "            else:\n",
    "                phon_list[np.argmax(sum_all_layers[i, :])] += phon\n",
    "        elif discard_next:\n",
    "            discard_next = False\n",
    "\n",
    "    # test = np.where(np.array(phon_list) == phon)[0]\n",
    "    #     if len(test > 1):\n",
    "    #         phon_list[np.max(test)] = \"%\"\n",
    "\n",
    "    ##NOT WORKING PROPERLY\n",
    "\n",
    "    # Creates the g_p tupple list\n",
    "    g_p = [(l, phon_list[i]) for i, l in enumerate(inp_text)]\n",
    "\n",
    "    # Creates the final g_p mapping\n",
    "    mapping = []\n",
    "    for phon, letters in groupby(g_p, lambda x: x[1]):\n",
    "        graph = \"\".join([letter[0] for letter in letters])\n",
    "        mapping.append(graph + \"~\" + phon)\n",
    "\n",
    "    return [\"\".join(inp_text), \" \".join(out_text), mapping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_attention_matrix(inp_text, out_text, sum_all_layers):              \n",
    "    from matplotlib import pyplot as plt\n",
    "    source_len = len(inp_text)\n",
    "    prediction_len = len(out_text)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(\n",
    "      X=sum_all_layers,\n",
    "      interpolation=\"nearest\",\n",
    "      cmap=plt.cm.Blues)\n",
    "    plt.xticks(np.arange(source_len), inp_text, rotation=45)\n",
    "    plt.yticks(np.arange(prediction_len), out_text, rotation=-45)\n",
    "    fig.tight_layout()\n",
    "    #fig.suptitle((\"\").join(inp_text) + \" \" + (\" \").join(temp), fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAI4CAYAAACGHoanAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAAMJYQAgDGEkIAwFhCCAAY6/8DJrnAXsnGc0kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe64a405390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = \"retard\"\n",
    "\n",
    "# get TensorFlow server connection parameters\n",
    "server_name, server_port = \"0.0.0.0\", \"9000\"\n",
    "\n",
    "# open channel to tensorflow server\n",
    "stub = _open_tf_server_channel(server_name, server_port)\n",
    "\n",
    "# get phonetic translation and attention matrices\n",
    "phon, sum_all_layers = _make_prediction(input, MODEL_NAME, stub, VOCAB)\n",
    "\n",
    "# make prediction\n",
    "inp_text = input\n",
    "out_text = phon\n",
    "plot_attention_matrix(inp_text, out_text, sum_all_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base threshold\n",
    "# fr : 0.75\n",
    "# es : 0.4\n",
    "if len(out_text) > 4:\n",
    "    threshold = 0.4\n",
    "else:\n",
    "    threshold = 0\n",
    "\n",
    "# While we have too many silent_letters detected\n",
    "while (True):\n",
    "    # Gets the silent_letters indices\n",
    "    # We consider that a letter is silent if its attention value is below mean attention + threshold * std attention\n",
    "    silent_letters_idx = [i for i, idx in enumerate(np.argmax(sum_all_layers, axis=0))\n",
    "                          if sum_all_layers[idx, i] < np.mean(sum_all_layers[idx, :])\n",
    "                          + threshold * np.std(sum_all_layers[idx, :])]\n",
    "    # Reduces threshold if too many silent letters are detected\n",
    "    # Can happen in french when we have 3 lettres graphemes\n",
    "    if len(silent_letters_idx) > 1 / 3 * len(inp_text):\n",
    "        threshold -= 0.1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Creates the phoneme attribution list\n",
    "phon_list = np.array(out_text)[np.argmax(sum_all_layers, axis=0)]\n",
    "phon_list[silent_letters_idx] = \"#\"  # \"#\" is our encoding for silent letters\n",
    "phon_list = phon_list.tolist()  # needed for the += just below\n",
    "\n",
    "# Checks if all the phonemes are attributed and if they are only present the correct number of time in the list\n",
    "# If not, the phoneme is concatenated to its most probable neighbor\n",
    "# and the least probable phoneme is replaced by a silent letter (this can happen for small datasets)\n",
    "discard_next = False\n",
    "for i, phon in enumerate(out_text):\n",
    "    if phon not in phon_list and not discard_next:\n",
    "        probable_idx = np.argmax(sum_all_layers[i, :])\n",
    "        if (i+1) < len(out_text) and phon_list[probable_idx] == out_text[i+1]:\n",
    "            phon_list[probable_idx] = phon + phon_list[probable_idx]\n",
    "            discard_next = True\n",
    "        else:\n",
    "            phon_list[np.argmax(sum_all_layers[i, :])] += phon\n",
    "    elif discard_next:\n",
    "        discard_next = False\n",
    "\n",
    "# test = np.where(np.array(phon_list) == phon)[0]\n",
    "#     if len(test > 1):\n",
    "#         phon_list[np.max(test)] = \"%\"\n",
    "\n",
    "##NOT WORKING PROPERLY\n",
    "\n",
    "# Creates the g_p tupple list\n",
    "g_p = [(l, phon_list[i]) for i, l in enumerate(inp_text)]\n",
    "\n",
    "# Creates the final g_p mapping\n",
    "mapping = []\n",
    "for phon, letters in groupby(g_p, lambda x: x[1]):\n",
    "    graph = \"\".join([letter[0] for letter in letters])\n",
    "    mapping.append(graph + \"~\" + phon)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:1.5_cpu]",
   "language": "python",
   "name": "conda-env-1.5_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
