{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _load_model():\n",
    "    \"\"\"\n",
    "    Restore Checkpoint\n",
    "\n",
    "    :return: attention visualizer\n",
    "    \"\"\"\n",
    "    usr_dir.import_usr_dir('../submodule')\n",
    "\n",
    "    visualizer = visualization.AttentionVisualizer('transformer_base', 'transformer', \"data_dir\",\n",
    "                                                   'word_to_phonetic', beam_size=5)\n",
    "    tf.Variable(0, dtype=tf.int64, trainable=False, name='global_step')\n",
    "\n",
    "    sess = tf.train.MonitoredTrainingSession(\n",
    "        checkpoint_dir=\"../checkpoints/word_to_phonetic/transformer-transformer_base_single_gpu-fr-best_model\",\n",
    "        save_summaries_secs=0,\n",
    "    )\n",
    "\n",
    "    return sess, visualizer\n",
    "\n",
    "def _get_attention_matrices(input_word, sess, visualizer):\n",
    "    \"\"\"\n",
    "    Run model to get the attention matrices and phonetic text\n",
    "\n",
    "    :param input_word\n",
    "    :param sess: tf session\n",
    "    :param visualizer: attention visualizer\n",
    "    :return: inp_text, out_text(phonetic) and sum_all_layers\n",
    "    \"\"\"\n",
    "    _, inp_text, out_text, att_mats = visualizer.get_vis_data_from_string(sess, input_word)\n",
    "    inp_text = [str(c, 'Latin-1') for c in inp_text]  # Decodes Latin-1 because of Frenche and Spanish special chars\n",
    "    out_text = [str(c, 'Latin-1') for c in out_text]\n",
    "\n",
    "    # Removes both padding and \"end of sequence\" markers\n",
    "    inp_text = [v for v in inp_text if v != '<EOS>']\n",
    "    out_text = [v for v in out_text if v != '<EOS>' and v != '<pad>']\n",
    "\n",
    "    # Gets layes 0 and 4 of the \"inp_out\" matrices\n",
    "    att_matrices = np.array(attention._get_attention(inp_text, out_text, *att_mats)[\"inp_out\"][\"att\"])[np.array([0, 4]),\n",
    "                   :, :, :]\n",
    "\n",
    "    # Sum all attention heads\n",
    "    sum_all_head = np.sum(att_matrices, axis=1)\n",
    "\n",
    "    # Sum layers 0 and 4\n",
    "    sum_all_layers = _normalize(np.sum(sum_all_head, axis=0)[:len(out_text), :len(inp_text)])\n",
    "\n",
    "    return inp_text, out_text, sum_all_layers\n",
    "\n",
    "def _normalize(matrix):\n",
    "    \"\"\"\n",
    "        input: a numpy matrix\n",
    "        return: matrix with 0 mean and 1 std\n",
    "    \"\"\"\n",
    "    return (matrix - np.mean(matrix))/np.std(matrix)\n",
    "\n",
    "def _mapping(inp_text, out_text, sum_all_layers):\n",
    "    # Base threshold\n",
    "    # fr : 0.75\n",
    "    # es : 0.4\n",
    "    if len(out_text) > 4:\n",
    "        threshold = 0.75\n",
    "    else:\n",
    "        threshold = 0\n",
    "\n",
    "    # While we have too many silent_letters detected\n",
    "    while (True):\n",
    "        # Gets the silent_letters indices\n",
    "        # We consider that a letter is silent if its attention value is below mean attention + threshold * std attention\n",
    "        silent_letters_idx = [i for i, idx in enumerate(np.argmax(sum_all_layers, axis=0))\n",
    "                              if sum_all_layers[idx, i] < np.mean(sum_all_layers[idx, :])\n",
    "                              + threshold * np.std(sum_all_layers[idx, :])]\n",
    "        # Reduces threshold if too many silent letters are detected\n",
    "        # Can happen in french when we have 3 lettres graphemes\n",
    "        if len(silent_letters_idx) > 1 / 3 * len(inp_text):\n",
    "            threshold -= 0.1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Creates the phoneme attribution list\n",
    "    phon_list = np.array(out_text)[np.argmax(sum_all_layers, axis=0)]\n",
    "    phon_list[silent_letters_idx] = \"$\"  # \"$\" is our encoding for silent letters\n",
    "    phon_list = phon_list.tolist()  # needed for the += just below\n",
    "\n",
    "    # Checks if all the phonemes are attributed and if they are only present the correct number of time in the list\n",
    "    # If not, the phoneme is concatenated to its most probable neighbor\n",
    "    # and the least probable phoneme is replaced by a silent letter (this can happen for small datasets)\n",
    "    for i, phon in enumerate(out_text):\n",
    "        if phon not in phon_list:\n",
    "            phon_list[np.argmax(sum_all_layers[i, :])] += phon\n",
    "\n",
    "    # test = np.where(np.array(phon_list) == phon)[0]\n",
    "    #     if len(test > 1):\n",
    "    #         phon_list[np.max(test)] = \"%\"\n",
    "\n",
    "    ##NOT WORKING PROPERLY\n",
    "\n",
    "    # Creates the g_p tupple list\n",
    "    g_p = [(l, phon_list[i]) for i, l in enumerate(inp_text)]\n",
    "\n",
    "    # Creates the final g_p mapping\n",
    "    mapping = []\n",
    "    for phon, letters in groupby(g_p, lambda x: x[1]):\n",
    "        graph = \"\".join([letter[0] for letter in letters])\n",
    "        mapping.append(graph + \"-\" + phon)\n",
    "\n",
    "    return [\"\".join(inp_text), \"\".join(out_text), mapping]\n",
    "\n",
    "def _load_gp_prog(progression):\n",
    "    gpProg = pd.read_csv(os.path.join('../api/word_to_phonetic/fr/files/','gp_prog.csv'), sep=\";\")\n",
    "    gpProg.columns = [[\"GP\", \"LESSON\"]]\n",
    "    gpProg = gpProg.loc[gpProg[\"GP\"].notnull()]\n",
    "\n",
    "    return gpProg\n",
    "\n",
    "def _get_unique_words(wordGp):\n",
    "    uniqueWordList = []\n",
    "    for word, pred, gpMatch, copy in wordGp:\n",
    "        if (word, pred) not in uniqueWordList:\n",
    "            uniqueWordList.append((word, pred))\n",
    "        else:\n",
    "            wordGp.remove((word, pred, gpMatch, copy))\n",
    "    return wordGp\n",
    "\n",
    "\n",
    "def _generate_word_list(wordGp, gpProg):\n",
    "    \n",
    "    tempList = []\n",
    "    for i in range(len(gpProg)):\n",
    "        lesson = gpProg.loc[i]\n",
    "        \n",
    "        for word, pred, gpMatch, copy in wordGp[:]:\n",
    "            for gp in gpMatch[:]:\n",
    "                if gp == lesson[\"GP\"]:\n",
    "                    gpMatch.remove(gp)\n",
    "            if len(gpMatch) == 0:\n",
    "                tempList.append(((int(lesson[\"LESSON\"])),(\"\").join(word),(\".\").join(pred),(\".\").join(copy)))\n",
    "                wordGp.remove((word, pred, gpMatch, copy))\n",
    "    for word, pred, gpMatch, copy in wordGp[:]:\n",
    "        tempList.append((999,(\"\").join(word),(\".\").join(pred),(\".\").join(copy)))\n",
    "    \n",
    "    wordList = pd.DataFrame()\n",
    "    wordList = wordList.append(tempList,ignore_index=True)\n",
    "    wordList.columns = [[\"LESSON\", \"GRAPHEME\",\"PHONEME\", \"GPMATCH\"]]\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/anaconda3/envs/1.5_cpu/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from tensor2tensor.visualization import attention\n",
    "from tensor2tensor.visualization import visualization\n",
    "from tensor2tensor.utils import usr_dir\n",
    "from itertools import groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 9001 vs previous value: 9001. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "[['t', 'E', 's', 't'], ['v', 'a', 'l', 'E'], ['v', 'a', 'l', 'E']]\n",
      "[['t-t', 'e-E', 's-s', 't-t'], ['v-v', 'a-a', 'l-l', 'et-E'], ['v-v', 'a-a', 'l-l', 'aie-E', 'nt-$']]\n"
     ]
    }
   ],
   "source": [
    "# def g2p_mapping_file(corpus, progression):\n",
    "#gpProg = _load_gp_prog(\"progression\")\n",
    "#sess, visualizer = _load_model()\n",
    "\n",
    "corpus = ['test', 'valet', 'valaient']\n",
    "results = [_get_attention_matrices(word, sess, visualizer) for word in corpus]\n",
    "\n",
    "g_p_results = [_mapping(r[0], r[1], r[2])[2] for r in results]\n",
    "print([r[1] for r in results])\n",
    "print(g_p_results)\n",
    "\n",
    "wordGp = list(zip(corpus, [r[1] for r in results], deepcopy(g_p_results), deepcopy(g_p_results)))\n",
    "wordGp = _get_unique_words(wordGp)\n",
    "wordList = _generate_word_list(wordGp, gpProg)\n",
    "\n",
    "#return wordList.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#g2p_mapping_file(['test', 'valet', 'valaient'], '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:1.5_cpu]",
   "language": "python",
   "name": "conda-env-1.5_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
