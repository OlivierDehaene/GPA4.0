{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/anaconda3/envs/1.5_cpu/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.bin import t2t_decoder  # To register the hparams set\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.visualization import attention\n",
    "from tensor2tensor.visualization import visualization\n",
    "from tensor2tensor.utils import usr_dir\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Importing user module submodule from path /home/olivier/Bureau/Transformer_test\n"
     ]
    }
   ],
   "source": [
    "# PUT THE MODEL YOU WANT TO LOAD HERE!\n",
    "CHECKPOINT = \"../checkpoints/word_to_phonetic_vocab/transformer-transformer_base_single_gpu-en-best_model\"\n",
    "\n",
    "# HParams\n",
    "problem_name = 'word_to_phonetic_vocab'\n",
    "data_dir = \"../data_dir/en\"\n",
    "model_name = \"transformer\"\n",
    "hparams_set = \"transformer_base_single_gpu\"\n",
    "\n",
    "#Adding word to phonetic problem to the problem list\n",
    "submodule_dir = \"../submodule\"\n",
    "usr_dir.import_usr_dir(submodule_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_att_mats(translate_model):\n",
    "  \"\"\"Get's the tensors representing the attentions from a build model.\n",
    "\n",
    "  The attentions are stored in a dict on the Transformer object while building\n",
    "  the graph.\n",
    "\n",
    "  Args:\n",
    "    translate_model: Transformer object to fetch the attention weights from.\n",
    "\n",
    "  Returns:\n",
    "  Tuple of attention matrices; (\n",
    "      enc_atts: Encoder self attention weights.\n",
    "        A list of `num_layers` numpy arrays of size\n",
    "        (batch_size, num_heads, inp_len, inp_len)\n",
    "      dec_atts: Decoder self attetnion weights.\n",
    "        A list of `num_layers` numpy arrays of size\n",
    "        (batch_size, num_heads, out_len, out_len)\n",
    "      encdec_atts: Encoder-Decoder attention weights.\n",
    "        A list of `num_layers` numpy arrays of size\n",
    "        (batch_size, num_heads, out_len, inp_len)\n",
    "  )\n",
    "  \"\"\"\n",
    "  enc_atts = []\n",
    "  dec_atts = []\n",
    "  encdec_atts = []\n",
    "\n",
    "  prefix = 'transformer/body/'\n",
    "  postfix = '/multihead_attention/dot_product_attention'\n",
    "\n",
    "  for i in range(translate_model.hparams.num_hidden_layers):\n",
    "    enc_att = translate_model.attention_weights[\n",
    "        '%sencoder/layer_%i/self_attention%s' % (prefix, i, postfix)]\n",
    "    dec_att = translate_model.attention_weights[\n",
    "        '%sdecoder/layer_%i/self_attention%s' % (prefix, i, postfix)]\n",
    "    encdec_att = translate_model.attention_weights[\n",
    "        '%sdecoder/layer_%i/encdec_attention%s' % (prefix, i, postfix)]\n",
    "    enc_atts.append(enc_att)\n",
    "    dec_atts.append(dec_att)\n",
    "    encdec_atts.append(encdec_att)\n",
    "\n",
    "  return enc_atts, dec_atts, encdec_atts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(hparams_set, model_name, data_dir, problem_name, beam_size=1):\n",
    "  \"\"\"Build the graph required to featch the attention weights.\n",
    "\n",
    "  Args:\n",
    "    hparams_set: HParams set to build the model with.\n",
    "    model_name: Name of model.\n",
    "    data_dir: Path to directory contatining training data.\n",
    "    problem_name: Name of problem.\n",
    "    beam_size: (Optional) Number of beams to use when decoding a traslation.\n",
    "        If set to 1 (default) then greedy decoding is used.\n",
    "\n",
    "  Returns:\n",
    "    Tuple of (\n",
    "        inputs: Input placeholder to feed in ids to be translated.\n",
    "        targets: Targets placeholder to feed to translation when fetching\n",
    "            attention weights.\n",
    "        samples: Tensor representing the ids of the translation.\n",
    "        att_mats: Tensors representing the attention weights.\n",
    "    )\n",
    "  \"\"\"\n",
    "  hparams = trainer_lib.create_hparams(\n",
    "      hparams_set, data_dir=data_dir, problem_name=problem_name)\n",
    "  translate_model = registry.model(model_name)(\n",
    "      hparams, tf.estimator.ModeKeys.EVAL)\n",
    "\n",
    "  inputs = tf.placeholder(tf.int32, shape=(None, None, 1, 1), name='inputs')\n",
    "  targets = tf.placeholder(tf.int32, shape=(None, None, 1, 1), name='targets')\n",
    "  translate_model({\n",
    "      'inputs': inputs,\n",
    "      'targets': targets,\n",
    "  })\n",
    "\n",
    "  # Must be called after building the training graph, so that the dict will\n",
    "  # have been filled with the attention tensors. BUT before creating the\n",
    "  # interence graph otherwise the dict will be filled with tensors from\n",
    "  # inside a tf.while_loop from decoding and are marked unfetchable.\n",
    "  att_mats = get_att_mats(translate_model)\n",
    "\n",
    "  with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
    "    samples = translate_model.infer({\n",
    "        'inputs': inputs,\n",
    "    }, beam_size=beam_size)['outputs']\n",
    "\n",
    "  return inputs, targets, samples, att_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_model(saved_model_dir):\n",
    "    att_mat_inp_out_layer_0 = tf.squeeze(tf.reduce_sum(att_mats[2][0], axis=1))\n",
    "    att_mat_inp_out_layer_4 = tf.squeeze(tf.reduce_sum(att_mats[2][4], axis=1))\n",
    "    att_mat_inp_out_layer_5 = tf.squeeze(tf.reduce_sum(att_mats[2][5], axis=1))\n",
    "\n",
    "    input_get_phon = {'input': tf.saved_model.utils.build_tensor_info(inputs)}\n",
    "\n",
    "    output_get_phon = {'phon': tf.saved_model.utils.build_tensor_info(samples)}\n",
    "\n",
    "    signature_get_phon = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs=input_get_phon,\n",
    "        outputs=output_get_phon,\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    )\n",
    "\n",
    "    input_get_att_mats = {'input': tf.saved_model.utils.build_tensor_info(inputs),\n",
    "              'phon': tf.saved_model.utils.build_tensor_info(targets)}\n",
    "\n",
    "    output_get_att_mats = {'att_mat_inp_out_layer_0': tf.saved_model.utils.build_tensor_info(att_mat_inp_out_layer_0),\n",
    "                          'att_mat_inp_out_layer_4': tf.saved_model.utils.build_tensor_info(att_mat_inp_out_layer_4),\n",
    "                          'att_mat_inp_out_layer_5': tf.saved_model.utils.build_tensor_info(att_mat_inp_out_layer_5)}\n",
    "\n",
    "    signature_get_att_mats = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs=input_get_att_mats,\n",
    "        outputs=output_get_att_mats,\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    )\n",
    "\n",
    "    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "\n",
    "    # Save out the SavedModel.\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_dir)\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess, [tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            'get_phon': signature_get_phon,\n",
    "            'get_att_mats': signature_get_att_mats\n",
    "        },\n",
    "        legacy_init_op=legacy_init_op)\n",
    "    builder.save()\n",
    "        \n",
    "def _load_model(model_dir,saver ,sess):\n",
    "    import re\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(model_dir, ckpt_name))\n",
    "        counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\", ckpt_name)).group(0))\n",
    "        return True, counter\n",
    "    return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_158_512.bottom\n",
      "INFO:tensorflow:Transforming 'targets' with symbol_modality_158_512.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "WARNING:tensorflow:From /home/olivier/anaconda3/envs/1.5_cpu/lib/python3.5/site-packages/tensor2tensor/layers/common_layers.py:513: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_158_512.top\n",
      "WARNING:tensorflow:From /home/olivier/anaconda3/envs/1.5_cpu/lib/python3.5/site-packages/tensor2tensor/layers/common_layers.py:1708: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Beam Decoding with beam size 5\n",
      "WARNING:tensorflow:From /home/olivier/anaconda3/envs/1.5_cpu/lib/python3.5/site-packages/tensor2tensor/utils/beam_search.py:93: calling reduce_logsumexp (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from ../checkpoints/word_to_phonetic_vocab/transformer-transformer_base_single_gpu-en-best_model/model.ckpt-11000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 11000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, targets, samples, att_mats = build_model(hparams_set, model_name, data_dir, problem_name, beam_size = 5)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "_load_model(CHECKPOINT, saver, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'en/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "export_model(\"en\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:1.5_cpu]",
   "language": "python",
   "name": "conda-env-1.5_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
